{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "    Identify products at risk of backorder before the event occurs so the business has time to react. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Data file contains the historical data for the 8 weeks prior to the week we are trying to predict. The data was taken as weekly snapshots at the start of each week. Columns are defined as follows:\n",
    "\n",
    "    sku - Random ID for the product\n",
    "\n",
    "    national_inv - Current inventory level for the part\n",
    "\n",
    "    lead_time - Transit time for product (if available)\n",
    "\n",
    "    in_transit_qty - Amount of product in transit from source\n",
    "\n",
    "    forecast_3_month - Forecast sales for the next 3 months\n",
    "\n",
    "    forecast_6_month - Forecast sales for the next 6 months\n",
    "\n",
    "    forecast_9_month - Forecast sales for the next 9 months\n",
    "\n",
    "    sales_1_month - Sales quantity for the prior 1 month time period\n",
    "\n",
    "    sales_3_month - Sales quantity for the prior 3 month time period\n",
    "\n",
    "    sales_6_month - Sales quantity for the prior 6 month time period\n",
    "\n",
    "    sales_9_month - Sales quantity for the prior 9 month time period\n",
    "\n",
    "    min_bank - Minimum recommend amount to stock\n",
    "\n",
    "    potential_issue - Source issue for part identified\n",
    "\n",
    "    pieces_past_due - Parts overdue from source\n",
    "\n",
    "    perf_6_month_avg - Source performance for prior 6 month period\n",
    "\n",
    "    perf_12_month_avg - Source performance for prior 12 month period\n",
    "\n",
    "    local_bo_qty - Amount of stock orders overdue\n",
    "\n",
    "    deck_risk - Part risk flag\n",
    "\n",
    "    oe_constraint - Part risk flag\n",
    "\n",
    "    ppap_risk - Part risk flag\n",
    "\n",
    "    stop_auto_buy - Part risk flag\n",
    "\n",
    "    rev_stop - Part risk flag\n",
    "\n",
    "    went_on_backorder - Product actually went on backorder. This is the target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "#### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Yunus Saleem\\\\Desktop\\\\Insofe\\\\Class-35-25th August\\\\20180825_Batch42_CSE7321c_Lab01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For setting working directory, if required\n",
    "os.chdir('C:\\\\Users\\\\Yunus Saleem\\\\Desktop\\\\Insofe\\\\Class-35-25th August\\\\20180825_Batch42_CSE7321c_Lab01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BackOrders.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the number row and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61589, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'national_inv', 'lead_time', 'in_transit_qty',\n",
       "       'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
       "       'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month',\n",
       "       'min_bank', 'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
       "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
       "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=61589, step=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the top rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888279</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870557</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1475481</td>\n",
       "      <td>258</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>132</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1888279           117        NaN               0                 0   \n",
       "1  1870557             7        2.0               0                 0   \n",
       "2  1475481           258       15.0              10                10   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0                 0                 0              0              0   \n",
       "1                 0                 0              0              0   \n",
       "2                77               184             46            132   \n",
       "\n",
       "   sales_6_month        ...         pieces_past_due  perf_6_month_avg  \\\n",
       "0             15        ...                       0            -99.00   \n",
       "1              0        ...                       0              0.50   \n",
       "2            256        ...                       0              0.54   \n",
       "\n",
       "  perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "0            -99.00             0         No             No        Yes   \n",
       "1              0.28             0        Yes             No         No   \n",
       "2              0.70             0         No             No         No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows a quick statistic summary of your data using describe.\n",
    "\n",
    "For object data (e.g. strings or timestamps), the resultâ€™s index will include count, unique, top, and freq. \n",
    "\n",
    "The top is the most common value.\n",
    "\n",
    "The freq is the most common valueâ€™s frequency.\n",
    "\n",
    "Timestamps also include the first and last items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>58186.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48145</td>\n",
       "      <td>61577</td>\n",
       "      <td>53792</td>\n",
       "      <td>59303</td>\n",
       "      <td>61569</td>\n",
       "      <td>50296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.037188e+06</td>\n",
       "      <td>287.721882</td>\n",
       "      <td>7.559619</td>\n",
       "      <td>30.192843</td>\n",
       "      <td>1.692728e+02</td>\n",
       "      <td>3.150413e+02</td>\n",
       "      <td>4.535760e+02</td>\n",
       "      <td>44.742957</td>\n",
       "      <td>150.732631</td>\n",
       "      <td>2.835465e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-6.264182</td>\n",
       "      <td>-5.863664</td>\n",
       "      <td>1.205361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.564178e+05</td>\n",
       "      <td>4233.906931</td>\n",
       "      <td>6.498952</td>\n",
       "      <td>792.869253</td>\n",
       "      <td>5.286742e+03</td>\n",
       "      <td>9.774362e+03</td>\n",
       "      <td>1.420201e+04</td>\n",
       "      <td>1373.805831</td>\n",
       "      <td>5224.959649</td>\n",
       "      <td>8.872270e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>42.309229</td>\n",
       "      <td>25.537906</td>\n",
       "      <td>24.844514</td>\n",
       "      <td>29.981155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.068628e+06</td>\n",
       "      <td>-2999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.498574e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.898033e+06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.314826e+06</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.284895e+06</td>\n",
       "      <td>673445.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>170976.000000</td>\n",
       "      <td>1.126656e+06</td>\n",
       "      <td>2.094336e+06</td>\n",
       "      <td>3.062016e+06</td>\n",
       "      <td>295197.000000</td>\n",
       "      <td>934593.000000</td>\n",
       "      <td>1.799099e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sku   national_inv     lead_time  in_transit_qty  \\\n",
       "count   6.158900e+04   61589.000000  58186.000000    61589.000000   \n",
       "unique           NaN            NaN           NaN             NaN   \n",
       "top              NaN            NaN           NaN             NaN   \n",
       "freq             NaN            NaN           NaN             NaN   \n",
       "mean    2.037188e+06     287.721882      7.559619       30.192843   \n",
       "std     6.564178e+05    4233.906931      6.498952      792.869253   \n",
       "min     1.068628e+06   -2999.000000      0.000000        0.000000   \n",
       "25%     1.498574e+06       3.000000      4.000000        0.000000   \n",
       "50%     1.898033e+06      10.000000      8.000000        0.000000   \n",
       "75%     2.314826e+06      57.000000      8.000000        0.000000   \n",
       "max     3.284895e+06  673445.000000     52.000000   170976.000000   \n",
       "\n",
       "        forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
       "count       6.158900e+04      6.158900e+04      6.158900e+04   61589.000000   \n",
       "unique               NaN               NaN               NaN            NaN   \n",
       "top                  NaN               NaN               NaN            NaN   \n",
       "freq                 NaN               NaN               NaN            NaN   \n",
       "mean        1.692728e+02      3.150413e+02      4.535760e+02      44.742957   \n",
       "std         5.286742e+03      9.774362e+03      1.420201e+04    1373.805831   \n",
       "min         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "25%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "50%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "75%         1.200000e+01      2.500000e+01      3.600000e+01       6.000000   \n",
       "max         1.126656e+06      2.094336e+06      3.062016e+06  295197.000000   \n",
       "\n",
       "        sales_3_month  sales_6_month        ...         pieces_past_due  \\\n",
       "count    61589.000000   6.158900e+04        ...            61589.000000   \n",
       "unique            NaN            NaN        ...                     NaN   \n",
       "top               NaN            NaN        ...                     NaN   \n",
       "freq              NaN            NaN        ...                     NaN   \n",
       "mean       150.732631   2.835465e+02        ...                1.605400   \n",
       "std       5224.959649   8.872270e+03        ...               42.309229   \n",
       "min          0.000000   0.000000e+00        ...                0.000000   \n",
       "25%          0.000000   0.000000e+00        ...                0.000000   \n",
       "50%          2.000000   4.000000e+00        ...                0.000000   \n",
       "75%         17.000000   3.400000e+01        ...                0.000000   \n",
       "max     934593.000000   1.799099e+06        ...             7392.000000   \n",
       "\n",
       "        perf_6_month_avg perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
       "count       61589.000000      61589.000000  61589.000000      61589   \n",
       "unique               NaN               NaN           NaN          2   \n",
       "top                  NaN               NaN           NaN         No   \n",
       "freq                 NaN               NaN           NaN      48145   \n",
       "mean           -6.264182         -5.863664      1.205361        NaN   \n",
       "std            25.537906         24.844514     29.981155        NaN   \n",
       "min           -99.000000        -99.000000      0.000000        NaN   \n",
       "25%             0.620000          0.640000      0.000000        NaN   \n",
       "50%             0.820000          0.800000      0.000000        NaN   \n",
       "75%             0.960000          0.950000      0.000000        NaN   \n",
       "max             1.000000          1.000000   2999.000000        NaN   \n",
       "\n",
       "        oe_constraint  ppap_risk stop_auto_buy rev_stop went_on_backorder  \n",
       "count           61589      61589         61589    61589             61589  \n",
       "unique              2          2             2        2                 2  \n",
       "top                No         No           Yes       No                No  \n",
       "freq            61577      53792         59303    61569             50296  \n",
       "mean              NaN        NaN           NaN      NaN               NaN  \n",
       "std               NaN        NaN           NaN      NaN               NaN  \n",
       "min               NaN        NaN           NaN      NaN               NaN  \n",
       "25%               NaN        NaN           NaN      NaN               NaN  \n",
       "50%               NaN        NaN           NaN      NaN               NaN  \n",
       "75%               NaN        NaN           NaN      NaN               NaN  \n",
       "max               NaN        NaN           NaN      NaN               NaN  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                    int64\n",
       "national_inv           int64\n",
       "lead_time            float64\n",
       "in_transit_qty         int64\n",
       "forecast_3_month       int64\n",
       "forecast_6_month       int64\n",
       "forecast_9_month       int64\n",
       "sales_1_month          int64\n",
       "sales_3_month          int64\n",
       "sales_6_month          int64\n",
       "sales_9_month          int64\n",
       "min_bank               int64\n",
       "potential_issue       object\n",
       "pieces_past_due        int64\n",
       "perf_6_month_avg     float64\n",
       "perf_12_month_avg    float64\n",
       "local_bo_qty           int64\n",
       "deck_risk             object\n",
       "oe_constraint         object\n",
       "ppap_risk             object\n",
       "stop_auto_buy         object\n",
       "rev_stop              object\n",
       "went_on_backorder     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "sku is Categorical but is interpreted as int64 \n",
    "potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder are also \n",
    "categorical but is interpreted as object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all the attributes to appropriate type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type conversion\n",
    "\n",
    "    Using astype('category') to convert potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder attributes to categorical attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sku', 'potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']:\n",
    "    data[col] = data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                  category\n",
       "national_inv            int64\n",
       "lead_time             float64\n",
       "in_transit_qty          int64\n",
       "forecast_3_month        int64\n",
       "forecast_6_month        int64\n",
       "forecast_9_month        int64\n",
       "sales_1_month           int64\n",
       "sales_3_month           int64\n",
       "sales_6_month           int64\n",
       "sales_9_month           int64\n",
       "min_bank                int64\n",
       "potential_issue      category\n",
       "pieces_past_due         int64\n",
       "perf_6_month_avg      float64\n",
       "perf_12_month_avg     float64\n",
       "local_bo_qty            int64\n",
       "deck_risk            category\n",
       "oe_constraint        category\n",
       "ppap_risk            category\n",
       "stop_auto_buy        category\n",
       "rev_stop             category\n",
       "went_on_backorder    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete sku attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61589"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.unique(data.sku))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('sku', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "\n",
    "Missing value analysis and dropping the records with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv            0\n",
       "lead_time            3403\n",
       "in_transit_qty          0\n",
       "forecast_3_month        0\n",
       "forecast_6_month        0\n",
       "forecast_9_month        0\n",
       "sales_1_month           0\n",
       "sales_3_month           0\n",
       "sales_6_month           0\n",
       "sales_9_month           0\n",
       "min_bank                0\n",
       "potential_issue         0\n",
       "pieces_past_due         0\n",
       "perf_6_month_avg        0\n",
       "perf_12_month_avg       0\n",
       "local_bo_qty            0\n",
       "deck_risk               0\n",
       "oe_constraint           0\n",
       "ppap_risk               0\n",
       "stop_auto_buy           0\n",
       "rev_stop                0\n",
       "went_on_backorder       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the number of records before and after missing value records removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61589, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the number of missing values is about 5%. For initial analysis we ignore all these records\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national_inv         0\n",
      "lead_time            0\n",
      "in_transit_qty       0\n",
      "forecast_3_month     0\n",
      "forecast_6_month     0\n",
      "forecast_9_month     0\n",
      "sales_1_month        0\n",
      "sales_3_month        0\n",
      "sales_6_month        0\n",
      "sales_9_month        0\n",
      "min_bank             0\n",
      "potential_issue      0\n",
      "pieces_past_due      0\n",
      "perf_6_month_avg     0\n",
      "perf_12_month_avg    0\n",
      "local_bo_qty         0\n",
      "deck_risk            0\n",
      "oe_constraint        0\n",
      "ppap_risk            0\n",
      "stop_auto_buy        0\n",
      "rev_stop             0\n",
      "went_on_backorder    0\n",
      "dtype: int64\n",
      "----------------------------------\n",
      "(58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "print(\"----------------------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical to Numeric\n",
    "\n",
    "For some of the models all the independent attribute should be of type numeric and ANN model is one among them.\n",
    "But this data set has some categorial attributes.\n",
    "\n",
    "'pandas.get_dummies' To convert convert categorical variable into dummy/indicator variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
      "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
      "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating dummy variables.\n",
    "\n",
    "If we have k levels in a category, then we create k-1 dummy variables as the last one would be redundant. So we use the parameter drop_first in pd.get_dummies function that drops the first level in each of the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_Attributes = data.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(columns=categorical_Attributes, data=data, prefix=categorical_Attributes, prefix_sep=\"_\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
      "       'local_bo_qty', 'potential_issue_Yes', 'deck_risk_Yes',\n",
      "       'oe_constraint_Yes', 'ppap_risk_Yes', 'stop_auto_buy_Yes',\n",
      "       'rev_stop_Yes', 'went_on_backorder_Yes'],\n",
      "      dtype='object') (58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.columns, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47217\n",
       "1    10969\n",
       "Name: went_on_backorder_Yes, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['went_on_backorder_Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "Using sklearn.model_selection.train_test_split\n",
    "\n",
    "    Split arrays or matrices into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train test split on the data\n",
    "X, y = data.loc[:,data.columns!='went_on_backorder_Yes'].values, data.loc[:,'went_on_backorder_Yes'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify = data['went_on_backorder_Yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33052\n",
      "1     7678\n",
      "dtype: int64\n",
      "0    14165\n",
      "1     3291\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To get the distribution in the target in train and test\n",
    "print(pd.value_counts(y_train))\n",
    "print(pd.value_counts(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a logistic regression model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on train data\n",
    "train_pred = classifier.predict(X_train)\n",
    "# Predictions on test data\n",
    "test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Train Data: \n",
      " [[32952   100]\n",
      " [ 7226   452]]\n",
      "Confusion Matrix - Test Data: \n",
      " [[14125    40]\n",
      " [ 3083   208]]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "print(\"Confusion Matrix - Train Data: \\n\", confusion_matrix_train)\n",
    "# Test data\n",
    "confusion_matrix_test= confusion_matrix(y_test, test_pred)\n",
    "print(\"Confusion Matrix - Test Data: \\n\", confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.996974464480213\n",
      "Train Recall:  0.05886949726491274\n",
      "Train Precision:  0.8188405797101449\n",
      "Train Accuracy:  0.820132580407562\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for logistic regression model\n",
    "#Accuracy\n",
    "accuracy_Train_logReg = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_logReg = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_logReg)\n",
    "print(\"Train Recall: \",recall_Train_logReg)\n",
    "print(\"Train Precision: \",precision_Train_logReg)\n",
    "print(\"Train Accuracy: \",accuracy_Train_logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9971761383692199\n",
      "Test Recall:  0.06320267395928289\n",
      "Test Precision:  0.8387096774193549\n",
      "Test Accuracy:  0.8210930339138405\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_logReg = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_logReg = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_logReg)\n",
    "print(\"Test Recall: \",recall_Test_logReg)\n",
    "print(\"Test Precision: \",precision_Test_logReg)\n",
    "print(\"Test Accuracy: \",accuracy_Test_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fc_dense_layers_keras.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. \n",
    "\n",
    "* The keras sequential api enables us to build common yet complex neural network architectures flexibly\n",
    "\n",
    "* Objects of the Keras sequential class, can have multiple neural network layers stacked on top of one another\n",
    "\n",
    "![](img/keras_sequential_api.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, input_dim=100, activation='relu', ))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,114\n",
      "Trainable params: 7,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Compilation\n",
    "Before training a model, you need to configure the learning process, which is done via the compile method. receives three arguments\n",
    "\n",
    "* optimizer - An optimizer. An optimizer is an algorithm that uses this feedback signal, to actually update the weights so that the output from the network gets closer to the ground truth.\n",
    "* loss - A loss function. This is the objective that the model will try to minimize.\n",
    "* metrics - A list of error metrics. This is for users reference and does not add value to the weights calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the  fit function\n",
    "\n",
    "* epoch = one forward pass and one backward pass of all the training examples\n",
    "* batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_3_input to have shape (100,) but got array with shape (21,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-941642333685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_3_input to have shape (100,) but got array with shape (21,)"
     ]
    }
   ],
   "source": [
    "# NOTE : Don't run the following line of code as we do not yet have X_train and y_train\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Sequential()\n",
    "\n",
    "perceptron_model.add(Dense(1, input_dim=21, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40730/40730 [==============================] - 5s 116us/step - loss: 0.5092 - acc: 0.8321\n",
      "Epoch 2/30\n",
      "40730/40730 [==============================] - 2s 59us/step - loss: 0.4437 - acc: 0.8428\n",
      "Epoch 3/30\n",
      "40730/40730 [==============================] - 2s 55us/step - loss: 0.4018 - acc: 0.8555: 1s - los\n",
      "Epoch 4/30\n",
      "40730/40730 [==============================] - 2s 57us/step - loss: 0.4044 - acc: 0.8558\n",
      "Epoch 5/30\n",
      "40730/40730 [==============================] - 2s 58us/step - loss: 0.4325 - acc: 0.8559\n",
      "Epoch 6/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.3898 - acc: 0.8622\n",
      "Epoch 7/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.4022 - acc: 0.8598\n",
      "Epoch 8/30\n",
      "40730/40730 [==============================] - 2s 57us/step - loss: 0.4061 - acc: 0.8601\n",
      "Epoch 9/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.3981 - acc: 0.8636: 0s - loss: 0.3976 - acc: 0.86\n",
      "Epoch 10/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.3933 - acc: 0.8634\n",
      "Epoch 11/30\n",
      "40730/40730 [==============================] - 2s 57us/step - loss: 0.4237 - acc: 0.8630\n",
      "Epoch 12/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.4076 - acc: 0.8667\n",
      "Epoch 13/30\n",
      "40730/40730 [==============================] - 2s 60us/step - loss: 0.4468 - acc: 0.8614\n",
      "Epoch 14/30\n",
      "40730/40730 [==============================] - 2s 55us/step - loss: 0.5780 - acc: 0.8592\n",
      "Epoch 15/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.4043 - acc: 0.8725: 0s - loss: 0.4097 - ac\n",
      "Epoch 16/30\n",
      "40730/40730 [==============================] - 2s 58us/step - loss: 0.3994 - acc: 0.8694\n",
      "Epoch 17/30\n",
      "40730/40730 [==============================] - 2s 55us/step - loss: 0.3957 - acc: 0.8686\n",
      "Epoch 18/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.4021 - acc: 0.8678\n",
      "Epoch 19/30\n",
      "40730/40730 [==============================] - 2s 55us/step - loss: 0.4065 - acc: 0.8679\n",
      "Epoch 20/30\n",
      "40730/40730 [==============================] - 2s 54us/step - loss: 0.4064 - acc: 0.8673: 1s - loss:\n",
      "Epoch 21/30\n",
      "40730/40730 [==============================] - 2s 54us/step - loss: 0.4076 - acc: 0.8662\n",
      "Epoch 22/30\n",
      "40730/40730 [==============================] - 2s 52us/step - loss: 0.3997 - acc: 0.8690\n",
      "Epoch 23/30\n",
      "40730/40730 [==============================] - 2s 52us/step - loss: 0.4649 - acc: 0.8650\n",
      "Epoch 24/30\n",
      "40730/40730 [==============================] - 2s 53us/step - loss: 0.4223 - acc: 0.8740\n",
      "Epoch 25/30\n",
      "40730/40730 [==============================] - 2s 53us/step - loss: 0.4005 - acc: 0.8736\n",
      "Epoch 26/30\n",
      "40730/40730 [==============================] - 2s 55us/step - loss: 0.9661 - acc: 0.8088\n",
      "Epoch 27/30\n",
      "40730/40730 [==============================] - 2s 53us/step - loss: 0.4297 - acc: 0.8669\n",
      "Epoch 28/30\n",
      "40730/40730 [==============================] - 2s 51us/step - loss: 0.3951 - acc: 0.8723\n",
      "Epoch 29/30\n",
      "40730/40730 [==============================] - 2s 59us/step - loss: 0.3924 - acc: 0.8698\n",
      "Epoch 30/30\n",
      "40730/40730 [==============================] - 2s 56us/step - loss: 0.3901 - acc: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x256fccf2278>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model.fit(X_train, y_train, epochs=30, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32331   721]\n",
      " [ 4691  2987]]\n",
      "[[13812   353]\n",
      " [ 2028  1263]]\n"
     ]
    }
   ],
   "source": [
    "test_pred=perceptron_model.predict_classes(X_test)\n",
    "train_pred=perceptron_model.predict_classes(X_train)\n",
    "\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Accuracy, True Negative Rate and True Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9781858889023357\n",
      "Train TPR:  0.3890336025006512\n",
      "Train Accuracy:  0.8671249693100909\n",
      "-----------------------\n",
      "Test TNR:  0.9750794211083657\n",
      "Test TPR:  0.3837739288969918\n",
      "Test Accuracy:  0.8635999083409716\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "Accuracy_Test=(confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test= confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test= confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "\n",
    "mlp_model.add(Dense(12, input_dim=21, activation='relu', kernel_initializer='normal'))\n",
    "mlp_model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32584 samples, validate on 8146 samples\n",
      "Epoch 1/30\n",
      "32584/32584 [==============================] - 3s 90us/step - loss: 0.3931 - acc: 0.8461 - val_loss: 0.3373 - val_acc: 0.8725\n",
      "Epoch 2/30\n",
      "32584/32584 [==============================] - 2s 62us/step - loss: 0.3220 - acc: 0.8831 - val_loss: 0.3053 - val_acc: 0.8868\n",
      "Epoch 3/30\n",
      "32584/32584 [==============================] - 2s 65us/step - loss: 0.3057 - acc: 0.8899 - val_loss: 0.3014 - val_acc: 0.8917\n",
      "Epoch 4/30\n",
      "32584/32584 [==============================] - 2s 63us/step - loss: 0.2962 - acc: 0.8935 - val_loss: 0.2872 - val_acc: 0.8971\n",
      "Epoch 5/30\n",
      "32584/32584 [==============================] - 2s 65us/step - loss: 0.2900 - acc: 0.8968 - val_loss: 0.2847 - val_acc: 0.8965\n",
      "Epoch 6/30\n",
      "32584/32584 [==============================] - 2s 64us/step - loss: 0.2876 - acc: 0.8966 - val_loss: 0.2897 - val_acc: 0.8954\n",
      "Epoch 7/30\n",
      "32584/32584 [==============================] - 2s 64us/step - loss: 0.2900 - acc: 0.8943 - val_loss: 0.2856 - val_acc: 0.8966\n",
      "Epoch 8/30\n",
      "32584/32584 [==============================] - 2s 64us/step - loss: 0.2806 - acc: 0.8956 - val_loss: 0.2852 - val_acc: 0.8950\n",
      "Epoch 9/30\n",
      "32584/32584 [==============================] - 3s 78us/step - loss: 0.2697 - acc: 0.8984 - val_loss: 0.2835 - val_acc: 0.8975\n",
      "Epoch 10/30\n",
      "32584/32584 [==============================] - 2s 64us/step - loss: 0.2649 - acc: 0.9002 - val_loss: 0.2727 - val_acc: 0.8997\n",
      "Epoch 11/30\n",
      "32584/32584 [==============================] - 2s 58us/step - loss: 0.2671 - acc: 0.8986 - val_loss: 0.2716 - val_acc: 0.8988\n",
      "Epoch 12/30\n",
      "32584/32584 [==============================] - 2s 66us/step - loss: 0.2650 - acc: 0.9002 - val_loss: 0.2695 - val_acc: 0.8977\n",
      "Epoch 13/30\n",
      "32584/32584 [==============================] - 2s 69us/step - loss: 0.2623 - acc: 0.8992 - val_loss: 0.2691 - val_acc: 0.9000\n",
      "Epoch 14/30\n",
      "32584/32584 [==============================] - 2s 63us/step - loss: 0.2623 - acc: 0.9001 - val_loss: 0.2731 - val_acc: 0.9017\n",
      "Epoch 15/30\n",
      "32584/32584 [==============================] - 2s 68us/step - loss: 0.2562 - acc: 0.9019 - val_loss: 0.2651 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      "32584/32584 [==============================] - 3s 78us/step - loss: 0.2549 - acc: 0.9002 - val_loss: 0.2653 - val_acc: 0.9011\n",
      "Epoch 17/30\n",
      "32584/32584 [==============================] - 3s 78us/step - loss: 0.2555 - acc: 0.9005 - val_loss: 0.2730 - val_acc: 0.8975\n",
      "Epoch 18/30\n",
      "32584/32584 [==============================] - 3s 82us/step - loss: 0.2559 - acc: 0.8993 - val_loss: 0.2674 - val_acc: 0.8984\n",
      "Epoch 19/30\n",
      "32584/32584 [==============================] - 2s 74us/step - loss: 0.2524 - acc: 0.9004 - val_loss: 0.2649 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "32584/32584 [==============================] - 2s 57us/step - loss: 0.2527 - acc: 0.9012 - val_loss: 0.2697 - val_acc: 0.8979\n",
      "Epoch 21/30\n",
      "32584/32584 [==============================] - 2s 52us/step - loss: 0.2523 - acc: 0.8999 - val_loss: 0.2631 - val_acc: 0.8961\n",
      "Epoch 22/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2503 - acc: 0.9001 - val_loss: 0.2652 - val_acc: 0.8991\n",
      "Epoch 23/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2497 - acc: 0.9011 - val_loss: 0.2626 - val_acc: 0.9011\n",
      "Epoch 24/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2481 - acc: 0.9026 - val_loss: 0.2633 - val_acc: 0.9031\n",
      "Epoch 25/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2514 - acc: 0.9025 - val_loss: 0.2598 - val_acc: 0.9003\n",
      "Epoch 26/30\n",
      "32584/32584 [==============================] - 2s 49us/step - loss: 0.2474 - acc: 0.9013 - val_loss: 0.2584 - val_acc: 0.9007\n",
      "Epoch 27/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2456 - acc: 0.9030 - val_loss: 0.2570 - val_acc: 0.8988\n",
      "Epoch 28/30\n",
      "32584/32584 [==============================] - 2s 50us/step - loss: 0.2474 - acc: 0.9021 - val_loss: 0.2560 - val_acc: 0.9001\n",
      "Epoch 29/30\n",
      "32584/32584 [==============================] - 2s 51us/step - loss: 0.2465 - acc: 0.9018 - val_loss: 0.2591 - val_acc: 0.8997\n",
      "Epoch 30/30\n",
      "32584/32584 [==============================] - 2s 51us/step - loss: 0.2444 - acc: 0.9026 - val_loss: 0.2555 - val_acc: 0.9012\n"
     ]
    }
   ],
   "source": [
    "#model_history = ann_model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "model_history = mlp_model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13376/17456 [=====================>........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "train_pred = mlp_model.predict_classes(X_train)\n",
    "\n",
    "test_pred = mlp_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting evaluation metrics and evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32331   721]\n",
      " [ 4691  2987]]\n",
      "[[13812   353]\n",
      " [ 2028  1263]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy, True Positive Rate and True Negative Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.9781858889023357\n",
      "Train Recall:  0.3890336025006512\n",
      "Train Precision:  0.8055555555555556\n",
      "Train Accuracy:  0.8671249693100909\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for ann_model 1\n",
    "#Accuracy\n",
    "accuracy_Train_M1 = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_M1 = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_M1)\n",
    "print(\"Train Recall: \",recall_Train_M1)\n",
    "print(\"Train Precision: \",precision_Train_M1)\n",
    "print(\"Train Accuracy: \",accuracy_Train_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9750794211083657\n",
      "Test Recall:  0.3837739288969918\n",
      "Test Precision:  0.781559405940594\n",
      "Test Accuracy:  0.8635999083409716\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_M1 = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_M1 = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_M1)\n",
    "print(\"Test Recall: \",recall_Test_M1)\n",
    "print(\"Test Precision: \",precision_Test_M1)\n",
    "print(\"Test Accuracy: \",accuracy_Test_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25682013b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('Accuracy Plot')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2568208bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Loss Function Plot')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Hidden Layers\n",
    "\n",
    "We have to be careful about overfitting!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32584 samples, validate on 8146 samples\n",
      "Epoch 1/10\n",
      "32584/32584 [==============================] - 21s 651us/step - loss: 0.4764 - acc: 0.8122 - val_loss: 0.4754 - val_acc: 0.8048\n",
      "Epoch 2/10\n",
      "32584/32584 [==============================] - 11907s 365ms/step - loss: 0.4502 - acc: 0.8132 - val_loss: 0.4453 - val_acc: 0.8048\n",
      "Epoch 3/10\n",
      "32584/32584 [==============================] - 24s 724us/step - loss: 0.4139 - acc: 0.8132 - val_loss: 0.3993 - val_acc: 0.8048\n",
      "Epoch 4/10\n",
      "32584/32584 [==============================] - 26s 786us/step - loss: 0.3685 - acc: 0.8237 - val_loss: 0.3560 - val_acc: 0.8270\n",
      "Epoch 5/10\n",
      "32584/32584 [==============================] - 25s 770us/step - loss: 0.3280 - acc: 0.8512 - val_loss: 0.3163 - val_acc: 0.8576\n",
      "Epoch 6/10\n",
      "32584/32584 [==============================] - 21s 643us/step - loss: 0.2987 - acc: 0.8667 - val_loss: 0.2918 - val_acc: 0.8680\n",
      "Epoch 7/10\n",
      "32584/32584 [==============================] - 30s 917us/step - loss: 0.2790 - acc: 0.8777 - val_loss: 0.2774 - val_acc: 0.8744\n",
      "Epoch 8/10\n",
      "32584/32584 [==============================] - 34s 1ms/step - loss: 0.2671 - acc: 0.8843 - val_loss: 0.2679 - val_acc: 0.8807\n",
      "Epoch 9/10\n",
      "32584/32584 [==============================] - 27s 840us/step - loss: 0.2602 - acc: 0.8887 - val_loss: 0.2634 - val_acc: 0.8840\n",
      "Epoch 10/10\n",
      "32584/32584 [==============================] - 28s 863us/step - loss: 0.2556 - acc: 0.8917 - val_loss: 0.2586 - val_acc: 0.8882\n",
      "Confusion matrices:\n",
      "---------------------\n",
      "Confusion matrix - Train:\n",
      "[[31467  1585]\n",
      " [ 2829  4849]]\n",
      "Confusion matrix - Test:\n",
      "[[13455   710]\n",
      " [ 1244  2047]]\n",
      "---------------------\n",
      "Evaluation metrics on train data for new model:\n",
      "------------------------------------\n",
      "Train Specificity:  0.952045262011376\n",
      "Train Recall:  0.6315446730919511\n",
      "Train Precision:  0.7536524712465029\n",
      "Train Accuracy:  0.8916277927817333\n",
      "------------------------------------\n",
      "Evaluation metrics on train data for model 1:\n",
      "Train Specificity:  0.9781858889023357\n",
      "Train Recall:  0.3890336025006512\n",
      "Train Precision:  0.8055555555555556\n",
      "Train Accuracy:  0.8671249693100909\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Evaluation metrics on test data for new model:\n",
      "------------------------------------\n",
      "Test Specificity:  0.9498764560536533\n",
      "Test Recall:  0.6219993922819812\n",
      "Test Precision:  0.7424737033006892\n",
      "Test Accuracy:  0.8880614115490376\n",
      "------------------------------------\n",
      "Evaluation metrics on test data for model 1:\n",
      "Test Specificity:  0.9750794211083657\n",
      "Test Recall:  0.3837739288969918\n",
      "Test Precision:  0.781559405940594\n",
      "Test Accuracy:  0.8635999083409716\n",
      "------------------------------------\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ann_model_hiddenExp = Sequential()\n",
    "\n",
    "# Adding more hidden layers\n",
    "ann_model_hiddenExp.add(Dense(1000, input_dim=21, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(500, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(100, activation='sigmoid', kernel_initializer='normal'))\n",
    "ann_model_hiddenExp.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "\n",
    "ann_model_hiddenExp.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "ann_model_hiddenExp.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Predictions\n",
    "train_pred = ann_model_hiddenExp.predict_classes(X_train)\n",
    "test_pred = ann_model_hiddenExp.predict_classes(X_test)\n",
    "\n",
    "#Evaluation metrics\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(\"Confusion matrices:\")\n",
    "print(\"---------------------\")\n",
    "print(\"Confusion matrix - Train:\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"Confusion matrix - Test:\")\n",
    "print(confusion_matrix_test)\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Metrics on train data\n",
    "#Accuracy\n",
    "accuracy_Train_hiddenExp = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_hiddenExp = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_hiddenExp = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_hiddenExp = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Evaluation metrics on train data for new model:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"Train Specificity: \",specificity_Train_hiddenExp)\n",
    "print(\"Train Recall: \",recall_Train_hiddenExp)\n",
    "print(\"Train Precision: \",precision_Train_hiddenExp)\n",
    "print(\"Train Accuracy: \",accuracy_Train_hiddenExp)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print(\"Evaluation metrics on train data for model 1:\")\n",
    "print(\"Train Specificity: \",specificity_Train_M1)\n",
    "print(\"Train Recall: \",recall_Train_M1)\n",
    "print(\"Train Precision: \",precision_Train_M1)\n",
    "print(\"Train Accuracy: \",accuracy_Train_M1)\n",
    "print(\"------------------------------------\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_hiddenExp = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_hiddenExp = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_hiddenExp = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_hiddenExp = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Evaluation metrics on test data for new model:\")\n",
    "print(\"------------------------------------\")\n",
    "print(\"Test Specificity: \",specificity_Test_hiddenExp)\n",
    "print(\"Test Recall: \",recall_Test_hiddenExp)\n",
    "print(\"Test Precision: \",precision_Test_hiddenExp)\n",
    "print(\"Test Accuracy: \",accuracy_Test_hiddenExp)\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print(\"Evaluation metrics on test data for model 1:\")\n",
    "print(\"Test Specificity: \",specificity_Test_M1)\n",
    "print(\"Test Recall: \",recall_Test_M1)\n",
    "print(\"Test Precision: \",precision_Test_M1)\n",
    "print(\"Test Accuracy: \",accuracy_Test_M1)\n",
    "print(\"------------------------------------\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Experiment with learning rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
